<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Ares Koumblis | Senior Autopilot Software Engineer</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <div class="container">
    <header>
      <img src="assets/photo.png" alt="Ares Koumblis" class="profile-pic" />
      <h1>Ares Koumblis</h1>
      <p><strong>Senior Autopilot Software Engineer @ Tesla</strong></p>
      <p>
         <a href="assets/Ares_Koumblis_CV.pdf" target="_blank">CV</a> |
         <a href="https://scholar.google.com/citations?user=9MrUlt8AAAAJ" target="_blank">Google Scholar</a> |
         <a href="https://github.com/ArisKoublis" target="_blank">GitHub</a>
      </p>
    </header>

    <section>
      <h2>About Me</h2>
      <p>
        Hi! I am Ares Koumblis (Greek: Άρης Κουμπλής), a Senior Autopilot Software Engineer at Tesla, working on the 
        evaluation and reinforcement learning fine-tuning of end-to-end autonomous driving models. I hold a BE/ME in 
        Electrical and Computer Engineering from the National Technical University of Athens, with a concentration in 
        Computer Science. While there, I founded and led the Formula Student (FSAE) autonomous driving team within 
        <a href="https://promracingteam.com/" target="_blank">PROM Racing NTUA</a>. My thesis focused on the autonomous 
        driving pipeline deployed on the team's first driverless car, advised by 
        <a href="https://robotics.ntua.gr/members/ktzaf/" target="_blank">Prof. Constantinos Tzafestas</a>.
      </p>
      <p>
        I am particularly interested in efficient use of limited resources in autonomous systems. In Formula Student, 
        we lacked the funds for a LiDAR sensor, so we developed a camera-only perception system and creatively accumulated 
        ground-truth depth data for training. At Tesla, I work on behavior tuning under reduced visibility, where imitation 
        of large-scale driving data is not feasible due to differences between driver perception and camera input.
      </p>
      <p>
        These experiences motivate my curiosity in methods that maximize learning efficiency and adaptability. I am 
        fascinated by how vision-language models can help autonomous systems make the most of existing resources. By 
        grounding control policies in semantic understanding of the environment, these models allow vehicles to adapt 
        to new tasks and instructions without retraining everything from scratch. This opens the door to more flexible, 
        interpretable, and efficient autonomous behavior, whether for scene-specific maneuvers, language-guided instructions, 
        or robust decision-making under uncertainty.
      </p>
    </section>

    <section>
      <h2>Projects</h2>
      <p> 
        The full autonomous driving software of P23, PROM Racing NTUA's first driverless car:
        <a href="https://github.com/prom-racing-ntua/P23-DV" target="_blank">GitHub link </a>
      </p>
      <p>
        An additional detection head to the existing YOLOv8-based perception pipeline to enable distance (range) estimation 
        for each detected Formula Student cone:
        <a href="https://github.com/ultralytics/ultralytics/pull/22409" target="_blank">GitHub link </a>
      </p>
    </section>

    <section>
      <h2>Articles</h2>
      <p>Koumplis, Aris. "Contribution to the Design and Implementation of an Autonomous Driving System for a Formula Student Driverless Car." (2024).</p>
    </section>

    <footer>
      <p>© 2025 Ares Koumblis</p>
    </footer>
  </div>
</body>
</html>
