<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Ares Koumblis | Senior Autopilot Software Engineer</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <div class="container">
    <header>
      <img src="assets/photo.png" alt="Ares Koumblis" class="profile-pic" />
      <h1>Ares Koumblis</h1>
      <p><strong>Senior Autopilot Software Engineer @ Tesla</strong></p>
      <p>
         <a href="assets/Ares_Koumblis_CV.pdf" target="_blank">CV</a> |
         <a href="https://scholar.google.com/citations?user=9MrUlt8AAAAJ" target="_blank">Google Scholar</a> |
         <a href="https://github.com/ArisKoublis" target="_blank">GitHub</a>
      </p>
    </header>

    <section>
      <h2>About Me</h2>
      <p>
        Hi! I am Ares Koumblis (Greek: Άρης Κουμπλής), a Senior Autopilot Software Engineer at Tesla, working on the 
        evaluation and Reinforcement Learning fine-tuning of end-to-end autonomous driving models. I hold a BE/ME in 
        Electrical and Computer Engineering from the National Technical University of Athens with a concentration on
        Computer Science. While there, I founded and led the Formula Student (FSAE) autonomous driving team within
        PROM Racing NTUA. My thesis statement was about the autonomous driving pipeline deployed on the team's first 
        driverless car, advised by <a href="https://robotics.ntua.gr/members/ktzaf/" target="_blank">Prof. Constantinos Tzafestas</a>.
      </p>
      <p>
        I am particularly interested in efficient use of limited resources in autonomous systems. In my Formula 
        Student team we lacked the funds to buy a LiDAR sensor so we competed with a camera-only perception system and 
        creatively accumulated ground-truth depth data for training. In Tesla, I work on behavior tuning under reduced 
        visibility, one of the few projects where imitation of the vast amounts of customer and expert driving data is not 
        an option, due to the mismatch between the driver's and the camera's visibility.
      </p>
      <p>
        I am fascinated by how vision-language models can help autonomous systems make the most of existing resources. 
        By grounding control policies in semantic understanding of the environment, these models allow vehicles to adapt 
        to new tasks and instructions without retraining everything from scratch. This approach opens the door to more 
        flexible, interpretable, and efficient autonomous behavior, whether for scene-specific maneuvers, language-guided 
        instructions, or robust decision-making under uncertainty.
      </p>
    </section>

    <section>
      <h2>Projects</h2>
      <p> 
        An additional detection head to the existing YOLOv8-based perception pipeline to enable distance (range) estimation for each detected Formula Student cone:
        <a href="https://github.com/ultralytics/ultralytics/pull/22409" target="_blank">GitHub link </a>
      </p>
    </section>

    <section>
      <h2>Articles</h2>
      <p>Koumplis, Aris. "Contribution to the Design and Implementation of an Autonomous Driving System for a Formula Student Driverless Car." (2024).</p>
    </section>

    <section>
      <h2>Interests</h2>
      <p>Machine Learning • Autonomous Systems • Robotics • Control Theory • Motion Planning • AI Safety</p>
    </section>

    <footer>
      <p>© 2025 Ares Koumblis</p>
    </footer>
  </div>
</body>
</html>
